# Hoy empiezo con IA Generativa

Â¡Hola developer! Este repo contiene todo lo que necesitas para empezar a trabajar con IA generativa. Desde quÃ© puedes usar para empezar gratis en tu mÃ¡quina local, o en la nube, hasta ejemplos de los diferentes conceptos que necesitas aprender para poder usar IA generativa en tus proyectos. La idea de este repo es llevarlo a una serie de casos prÃ¡cticos que te ayuden a entender cÃ³mo funciona la IA generativa pero tambiÃ©n que sirva para algo Ãºtil ðŸ¤“. En mi caso lo voy a basar en diferentes necesidades que tengo a la hora de publicar un nuevo vÃ­deo. Pero... empecemos por el principio.

## Â¿QuÃ© es IA generativa?

La IA generativa es un tipo de inteligencia artificial que puede crear contenido nuevo y original, como texto, imÃ¡genes, mÃºsica y mÃ¡s. Utiliza algoritmos avanzados y modelos de aprendizaje profundo para generar resultados creativos y Ãºnicos.

## Â¿QuÃ© puedes hacer con IA generativa?

- Generar texto: Puedes crear artÃ­culos, historias, poemas y mÃ¡s utilizando modelos de lenguaje como GPT-3.
- Crear imÃ¡genes: Puedes generar imÃ¡genes y arte utilizando modelos como DALL-E o Midjourney.
- Componer mÃºsica: Puedes crear melodÃ­as y composiciones musicales utilizando IA generativa.
- Automatizar tareas: Puedes utilizar IA generativa para automatizar tareas repetitivas y mejorar la eficiencia en el trabajo.
- Crear chatbots: Puedes desarrollar chatbots inteligentes que interactÃºan con los usuarios de manera natural.
- Generar cÃ³digo: Puedes utilizar IA generativa para escribir y depurar cÃ³digo, lo que puede acelerar el proceso de desarrollo.
- Mejorar la creatividad: Puedes utilizar IA generativa como una herramienta para inspirarte y mejorar tu creatividad en diferentes campos.
- Generar contenido personalizado: Puedes crear contenido adaptado a las preferencias y necesidades de los usuarios.

Y estos son solo algunos ejemplos. Pero lo importante aquÃ­ es que entiendas que la IA Generativa tiene como principal objetivo crear.

Vale, Â¿y cÃ³mo empiezo con todo esto? La IA Generativa utiliza lo que se conocen modelos que estÃ¡n entrenados, mejor o peor, para saber crear todo esto. Hay de diferentes tipos, tamaÃ±os y proveedores. AsÃ­ que vamos a empezar por ver cÃ³mo puedo montarme un entorno donde pueda probar estos modelos para en posteriores vÃ­deos elegir unos u otros dependiendo de lo que necesite.

## Â¿QuÃ© necesitas para empezar?

Lo primero que necesitas es un entorno de desarrollo y lo mÃ¡s importante de todo es que necesitas "algo" que pueda ejecutar los modelos de IA Generativa. AquÃ­ ðŸ‘‡ðŸ» te dejo algunas opciones:

- Ollama: Ollama es una herramienta de cÃ³digo abierto que te permite ejecutar modelos de IA generativa en tu mÃ¡quina local. Puedes instalarla fÃ¡cilmente y empezar a usarla con solo unos pocos comandos. [Ollama](https://ollama.com/)
- Docker Model Runner: Relativamente nuevo y no estÃ¡ soportado todavÃ­a en todos los sistemas operativos o arquitecturas pero si eres un desarrollador que trabaja con contenedores, puede ser una opciÃ³n interesante para explorar. [Docker Model Runner](https://www.docker.com/)
- GitHub Models: esta Ãºltima opciÃ³n, tambiÃ©n gratuita, te permite poder acceder a una variedad de modelos de IA generativa que puedes utilizar directamente en tus proyectos en fase de desarrollo y no necesitas instalar nada adicional. [GitHub Models](https://github.com/)

# Ollama

Puedes instalarlo localmente, por ejemplo en tu Mac a travÃ©s de Homebrew:

```bash
brew install ollama
```

O descargandote los ejecutables directamente desde su [pÃ¡gina de descargas](https://ollama.com/download).

TambiÃ©n puedes ejecutarlo dentro de un Dev Container, lo cual te evita tener que instalarlo directamente en tu mÃ¡quina local. Sin embargo, debes tener en cuenta de que para la mayorÃ­a de modelos que es humanamente posible ejecutarlos en una mÃ¡quina local, vas a necesitar reservar unos 16gb, como poco, de memoria RAM para que pueda ejecutar los modelos. Si quieres probarlo, este repositorio tiene todo lo que necesitas para tenerlo funcionando si abres el mismo dentro de un contenedor.

Si estÃ¡s en local, una vez que ya lo tengas instalado, necesitas primeramente arrancar ollama:

```bash
ollama serve
```

Si estÃ¡s dentro de un dev container, no es necesario que lo hagas, ya que el contenedor ya lo tiene arrancado.

Con esto tienes arrancada la herramienta que va a permitirte ejecutar los modelos de IA generativa en tu mÃ¡quina local. Pero por ahora no tienes ningÃºn modelo descargado que poder ejecutar. Para ello, muy al estilo Docker, puedes descargar modelos usando `ollama pull` y ejecutarlos con `ollama run`. Ok, pero quÃ© modelos puedo descargar? Puedes ver una lista de los modelos disponibles ejecutando el siguiente comando:



```bash
ollama list
```


y descargar alguno de los modelos, por ejemplo el de Mistral (no te preocupes, ya veremos mÃ¡s adelante quÃ© modelos son los que vas a ir necesitando)

```bash
ollama pull mistral
```

Para ver cuÃ¡ntos modelos tienes descargados, puedes ejecutar el siguiente comando:

```bash
ollama list


Ok, Â¿y ahora quÃ© hago con esto? Puedes ejecutar este modelo en concreto:

```bash
ollama run mistral "Â¿QuÃ© es IA generativa?"
```

O incluso lo puedes ejecutar para que puedas llamarlo de forma programÃ¡tica, a travÃ©s de un API REST:

```bash
ollama run mistral
```

Para saber quÃ© modelos tienes ejecutandose, puedes lanzar el siguiente comando:

```bash
ollama ps
```

Y a partir de este momento tambiÃ©n puedes hacer peticiones a travÃ©s de un cliente HTTP, como Postman o Insomnia, o incluso desde tu propio cÃ³digo. 

```bash
curl http://localhost:11434/api/generate \
-d '{ "model": "mistral", "stream": false, "prompt":"Mejorame este tÃ­tulo para un vÃ­deo de YouTube con emojis: Hoy empiezo con IA Generativa"}' \
| jq .response
```

La lista de modelos disponibles para Ollama la puedes encontrar aquÃ­: https://ollama.com/library

Si quieres probar otros la forma es la misma:

```bash
ollama pull gemma3
```

```bash
ollama run gemma3 "Â¿QuÃ© es IA generativa?"
```

O incluso Deepsekk-r1 que estÃ¡ ahora muy de moda:

```bash
ollama run deepseek-r1 "Â¿QuÃ© es IA generativa?"
```

Al igual que en Docker, no hace falta hacer primeramente un `pull` del modelo, sino que puedes ejecutarlo directamente y si no tienes el modelo en local se encargarÃ¡ de descargarlo.
## Docker Model Runner

Esta otra opciÃ³n estÃ¡ todavÃ­a en fase beta y no estÃ¡ soportada en todos los sistemas operativos o arquitecturas. Pero lo Ãºnico que debes hacer en este caso, si tienes instalado Docker Desktop es tenerlo actualizado, al menos a la versiÃ³n 


El "problema" de estos dos primeros es que necesitas hardware suficiente para poder ejecutar los modelos en tu local y que esto no sea un sufrimiento. Por ejemplo, en el repo de GitHub de ollama se indica lo siguiente:

> [Note]
>You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.