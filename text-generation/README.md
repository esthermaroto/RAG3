# Generaci칩n de texto con IA Generativa

춰Hola developer 游녦游낕! En esta secci칩n vas a poder aprender c칩mo trabajar con modelos de IA Generativa para pedirles que te ayuden a generar texto en base a uno que t칰 le pases. Adem치s vamos aprovechar este cap칤tulo para introducir algunos conceptos que son 칰tiles cuando comienzas en este mundo. El v칤deo relacionado con este contenido puedes encontrarlo en mi canal de YouTube:

[![creando textos con IA Generativa](https://github.com/user-attachments/assets/308be690-a399-490a-a9c9-74f47652abcc)](https://youtu.be/-FZtKYuDsgQ)

춰No te olvides de suscribirte a mi canal 游!

## Introducci칩n

La generaci칩n de texto con IA es un campo de la inteligencia artificial que se centra en la creaci칩n de modelos que puedan generar texto de forma aut칩noma. Estos modelos se entrenan en grandes cantidades de texto y luego se les pide que generen texto en funci칩n de una entrada dada. La generaci칩n de texto con IA se utiliza en una amplia variedad de aplicaciones, como la generaci칩n de contenido para sitios web, la creaci칩n de di치logos para chatbots y la redacci칩n de informes y art칤culos. Para mi ejemplo voy a tener como objetivo *mejorar t칤tulos de v칤deos para mi canal de YouTube*, de tal forma que puedas entender estos conceptos con un ejemplo pr치ctico.

## Qu칠 modelos utilizar

Lo primero que necesitas averiguar es qu칠 modelos de IA puedes utilizar para esta tarea. La forma m치s sencilla de averiguarlo es buscar en marketplaces como puede ser el de Ollama o en GitHub Models, o incluso usando la extensi칩n que te mostr칠 en el v칤deo anterior llamada [AI Toolkit for Visual Studio Code](https://learn.microsoft.com/es-es/windows/ai/toolkit/). En Github Models puedes encontrar de forma sencilla modelos buscando por `Capability`y eligiendo `Chat/completion` y ver치s que tenemos diferentes modelos que podemos usar. 쮺u치l elegir? Bueno, eso depende de tus necesidades y de tus recursos. Algunos modelos son m치s grandes y m치s potentes que otros, pero tambi칠n requieren m치s recursos para ejecutarse. Si est치s empezando, te recomiendo que pruebes con un modelo peque침o y luego vayas subiendo en complejidad a medida que te sientas m치s c칩mod@. Por ejemplo para este v칤deo voy a elegir cuatro modelos que est치n disponibles en GitHub Models:

- `Mistral NeMo`: es un modelo desarrollado por una star-up francesa, Mistral AI, en colaboraci칩n con NVIDIA. Est치 disponible bajo licencia Apache 2.0 (gratuito). La ventana de contexto es de 128.000 tokens, no es multimodal y soporta m칰ltiples idiomas.

- `GPT-4o`: es un modelo desarrollado por Open AI, una empresa de inteligencia artificial basada en San Francisco. Es un modelo de pago. Tiene una ventana de contexto de 128.000 tokens, es multimodal y soporta m칰ltiples idiomas.

- `Deepseek-R1`: es un modelo de lenguaje de 칰ltima generaci칩n desarrollado por DeepSeek AI, es un modelo gratuito pero tiene un versi칩n alojada en la nube. Tiene una ventana de contexto de 128.000 tokens, no es multimodal y se puede liar un poco si no le pides las cosas en ingl칠s o chino.

- `Phi-4`:  es un modelo desarrollado por Microsoft y es de pago. Tiene una ventana de contexto de 16.000 tokens, no es multimodal y soporta m칰ltiples idiomas.

Por otro lado, vamos a ver tambi칠n otros modelos, adem치s de estos, usando Ollama:

- `Gemma 3`: Es un modelo desarrollado por Google, es un modelo abierto, tiene una ventana de 128.000 tokens, puedes procesar tanto texto como im치genes y soporta m칰ltiples idiomas.

- `Llama 3.1`: Es un modelo desarrollado por Meta (Facebook), gratuito, soporta tambi칠n hasta 128.000 tokens y soporta m칰ltiples idiomas. No es multimodal.

## SDKs y APIs

Una vez que hayas elegido un modelo, necesitas averiguar c칩mo vas a interactuar con 칠l. Afortunadamente, hay muchas opciones disponibles, desde SDKs hasta APIs. Algunos modelos vienen con su propio SDK, pero si no es el caso, puedes utilizar un SDK gen칠rico como Hugging Face o OpenAI. Durante el v칤deo ver치s que utilizo tanto el de Mistral como el de OpenAI como puedes ver en el directorio `no_streaming`.

## Stream o no stream... That's the question!

Cuando est칠s trabajando con un modelo de IA generativa, es importante tener en cuenta si vas a trabajar en modo stream o no. Algunos modelos est치n dise침ados para trabajar en modo stream, lo que significa que puedes enviarles una entrada y obtener una salida en tiempo real. Otros modelos no est치n dise침ados para trabajar en modo stream, lo que significa que tienes que enviarles toda la entrada de una vez y luego esperar a que te devuelvan toda la salida. Los ejemplos del directorio `no_streaming` te muestran c칩mo es la experiencia del usuario cuando tienes que esperar que cuando lo vas recibiendo poco a poco. Por el contrario, en el directorio `with_streaming` podr치s ver c칩mo te devuelve el contenido de a pocos, seg칰n lo vaya generando el modelo de IA. Es habitual que en las interfaces de usuario se utilice el modo stream, mientras que en las aplicaciones de backend se utilice el modo no stream.

## Aplicaci칩n de ejemplo

Para finalizar con esta secci칩n, he creado una aplicaci칩n web que consta de dos partes:

- `web`: una aplicaci칩n muy simple, con solo HTML y JavaScript, sin frameworks ni nada, que representa una web en la que integro mi nueva funcionalidad de generaci칩n de t칤tulos para los v칤deos de mi canal de YouTube y que hace uso de una API para llamar a los modelos.
- `api`: API REST creada con Python y Flask, la cual recibe peticiones de la web y, dependendiendo de los par치metros recibidos llama a un modelo que est치 en GitHub Models o en Ollama.

Con este ejemplo puedes ver de forma sencilla c칩mo lo aprendido puede ser integrado en una aplicaci칩n que t칰 desarrolles, m치s all치 de los chat o playgrounds que te encuentres por ah칤 游땎

춰Nos vemos 游녦游낕!
