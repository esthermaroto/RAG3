# Generaci√≥n de texto con IA Generativa

¬°Hola developer üëãüèª! En esta secci√≥n vas a poder aprender c√≥mo trabajar con modelos de IA Generativa para pedirles que te ayuden a generar texto en base a uno que t√∫ le pases. Adem√°s vamos aprovechar este cap√≠tulo para introducir algunos conceptos que son √∫tiles cuando comienzas en este mundo. El v√≠deo relacionado con este contenido puedes encontrarlo en mi canal de YouTube:

[![creando textos con IA Generativa](https://github.com/user-attachments/assets/308be690-a399-490a-a9c9-74f47652abcc)](https://youtu.be/-FZtKYuDsgQ)

¬°No te olvides de suscribirte a mi canal ü•≤!

## Introducci√≥n

La generaci√≥n de texto con IA es un campo de la inteligencia artificial que se centra en la creaci√≥n de modelos que puedan generar texto de forma aut√≥noma. Estos modelos se entrenan en grandes cantidades de texto y luego se les pide que generen texto en funci√≥n de una entrada dada. La generaci√≥n de texto con IA se utiliza en una amplia variedad de aplicaciones, como la generaci√≥n de contenido para sitios web, la creaci√≥n de di√°logos para chatbots y la redacci√≥n de informes y art√≠culos. Para mi ejemplo voy a tener como objetivo *mejorar t√≠tulos de v√≠deos para mi canal de YouTube*, de tal forma que puedas entender estos conceptos con un ejemplo pr√°ctico.

## Qu√© modelos utilizar

Lo primero que necesitas averiguar es qu√© modelos de IA puedes utilizar para esta tarea. La forma m√°s sencilla de averiguarlo es buscar en marketplaces como puede ser el de Ollama o en GitHub Models, o incluso usando la extensi√≥n que te mostr√© en el v√≠deo anterior llamada [AI Toolkit for Visual Studio Code](https://learn.microsoft.com/es-es/windows/ai/toolkit/). En Github Models puedes encontrar de forma sencilla modelos buscando por `Capability`y eligiendo `Chat/completion` y ver√°s que tenemos diferentes modelos que podemos usar. ¬øCu√°l elegir? Bueno, eso depende de tus necesidades y de tus recursos. Algunos modelos son m√°s grandes y m√°s potentes que otros, pero tambi√©n requieren m√°s recursos para ejecutarse. Si est√°s empezando, te recomiendo que pruebes con un modelo peque√±o y luego vayas subiendo en complejidad a medida que te sientas m√°s c√≥mod@. Por ejemplo para este v√≠deo voy a elegir cuatro modelos que est√°n disponibles en GitHub Models:

- `Mistral NeMo`: es un modelo desarrollado por una star-up francesa, Mistral AI, en colaboraci√≥n con NVIDIA. Est√° disponible bajo licencia Apache 2.0 (gratuito). La ventana de contexto es de 128.000 tokens, no es multimodal y soporta m√∫ltiples idiomas.

- `GPT-4o`: es un modelo desarrollado por Open AI, una empresa de inteligencia artificial basada en San Francisco. Es un modelo de pago. Tiene una ventana de contexto de 128.000 tokens, es multimodal y soporta m√∫ltiples idiomas.

- `Deepseek-R1`: es un modelo de lenguaje de √∫ltima generaci√≥n desarrollado por DeepSeek AI, es un modelo gratuito pero tiene un versi√≥n alojada en la nube. Tiene una ventana de contexto de 128.000 tokens, no es multimodal y se puede liar un poco si no le pides las cosas en ingl√©s o chino.

- `Phi-4`:  es un modelo desarrollado por Microsoft y es de pago. Tiene una ventana de contexto de 16.000 tokens, no es multimodal y soporta m√∫ltiples idiomas.

Por otro lado, vamos a ver tambi√©n otros modelos, adem√°s de estos, usando Ollama:

- `Gemma 3`: Es un modelo desarrollado por Google, es un modelo abierto, tiene una ventana de 128.000 tokens, puedes procesar tanto texto como im√°genes y soporta m√∫ltiples idiomas.

- `Llama 3.1`: Es un modelo desarrollado por Meta (Facebook), gratuito, soporta tambi√©n hasta 128.000 tokens y soporta m√∫ltiples idiomas. No es multimodal.

## Ya tengo el modelo ¬øahora qu√©? APIs y SDKs

Una vez que hayas elegido un modelo, necesitas averiguar c√≥mo vas a interactuar con √©l. Afortunadamente, hay muchas opciones disponibles, desde APIs hasta SDKs. Lo habitual es que trabajes con un SDK en lugar de llamar a la API REST directamente para que sea m√°s sencillo. Algunos modelos vienen con su propio SDK, como el de Mistral, pero si no es el caso, puedes utilizar un SDK gen√©rico como Hugging Face o OpenAI. Durante el v√≠deo ver√°s que utilizo tanto el de Mistral como el de OpenAI como puedes ver en el directorio `no_streaming` y `with_streaming`

## Stream o no stream... That's the question!

Cuando est√©s trabajando con un modelo de IA generativa, es importante tener en cuenta si vas a trabajar en modo stream o no. Algunos modelos est√°n dise√±ados para trabajar en modo stream, lo que significa que puedes enviarles una entrada y obtener una salida en tiempo real. Otros modelos no est√°n dise√±ados para trabajar en modo stream, lo que significa que tienes que enviarles toda la entrada de una vez y luego esperar a que te devuelvan toda la salida. Los ejemplos del directorio `no_streaming` te muestran c√≥mo es la experiencia del usuario cuando tienes que esperar que cuando lo vas recibiendo poco a poco. Por el contrario, en el directorio `with_streaming` podr√°s ver c√≥mo te devuelve el contenido de a pocos, seg√∫n lo vaya generando el modelo de IA. Es habitual que en las interfaces de usuario se utilice el modo stream, mientras que en las aplicaciones de backend se utilice el modo no stream.

## Aplicaci√≥n de ejemplo

Para finalizar con esta secci√≥n, he creado una aplicaci√≥n web que consta de dos partes:

- `web`: una aplicaci√≥n muy simple, con solo HTML y JavaScript, sin frameworks ni nada, que representa una web en la que integro mi nueva funcionalidad de generaci√≥n de t√≠tulos para los v√≠deos de mi canal de YouTube y que hace uso de una API para llamar a los modelos.
- `api`: API REST creada con Python y Flask, la cual recibe peticiones de la web y, dependendiendo de los par√°metros recibidos llama a un modelo que est√° en GitHub Models o en Ollama.

Con este ejemplo puedes ver de forma sencilla c√≥mo lo aprendido puede ser integrado en una aplicaci√≥n que t√∫ desarrolles, m√°s all√° de los chat o playgrounds que te encuentres por ah√≠ üòÉ

¬°Nos vemos üëãüèª!
