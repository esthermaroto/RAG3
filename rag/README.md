# RAG (Retrieval-Augmented Generation)

Cuando hablamos de RAG (Generaci칩n mejorada por recuperaci칩n suena un poco raro 游땐) se trata de un proceso en el cual los modelos pueden dar mejor respuesta a la petici칩n que se les ha hecho porque pueden usar informaci칩n externa que no tiene por que ser informaci칩n con la que fueron entrenados previamente.


# 쮺칩mo funciona?

## 1. Crear datos externos

Antes de nada, necesitamos los datos externos que vamos a usar para mejorar la respuesta del modelo. Estos datos pueden ser de cualquier tipo, pero lo m치s com칰n es que sean documentos de texto, PDFs, etc. Siguiendo con mi ejemplo de mejorar mi canal de YouTube, lo que voy a hacer es utilizar como datos externos documentaci칩n de YouTube que est치 pensada para este fin: 

Como est치 en un formato HTML, lo que voy a hacer es utilizar una herramienta llamada [MarkItDown](https://github.com/microsoft/markitdown) que est치 pensada para convertir diferentes tipos de documentos e incluso URLs a un formato que sea m치s f치cil para los LLMs. Este m칩dulo ya forma parte del archivo `requirements.txt` de esta secci칩n por lo que solo tienes que instalarlo con `pip install -r requirements.txt` y ya lo tienes disponible.

```bash
cd rag
pip install -r requirements.txt
```

Una vez que lo tenemos instalado puedes ejecutar este archivo que tiene un conjunto de URLs de la documentaci칩n de YouTube que puede resultar interesante para mejorar las respuestas.

```bash
python 1.convert_urls.py
```

춰Perfecto! Ya tenemos un conjunto de documentos en formato Markdown que podemos usar para mejorar las respuestas del modelo. Al ejecutar este script se generar치 un directorio llamado `youtube_guides` que contendr치 los documentos en formato Markdown. Pero esto no es suficiente. Ahora lo que tenemos que hacer es convertir estos documentos a lo que se conoce como embeddings. Esto convertir치 estos documentos a un formato vectorial para lo cual tenemos modelos que nos pueden ayudar a hacer esta conversi칩n. Esta es la pinta que tienen estos documentos cuando los convertimos a embeddings:

```bash
python 2.convert_markdown.py
```

Si intentas hacer este proceso sin partir los docuemtos en partes m치s peque침as, es posible que te encuentres con un error de longitud m치xima. Aqu칤 tienes un ejemplo de c칩mo se ver칤a el error:

```bash
python 2.convert_markdown_sin_chunks.py
```

Ok, ya sabemos hacer embeddings. 쯏 ahora qu칠 hacemos con esto? lo que vamos a hacer es almacenarlos en una base de datos de tipo vectorial que he a침adido como parte de esta Dev Container. En este caso, he utilizado Qdrant, pero puedes usar cualquier otra base de datos de tipo vectorial.

Puedes ver su interfaz accediendo a [http://localhost:6333/dashboard](http://localhost:6333/dashboard) y podr치s ver lo que vamos almacenando. Por ahora no hay absolutamente nada. 

## 2. Almacenar los embeddings en la base de datos

Ahora que ya sabemos c칩mo convertir los documentos a embeddings, lo que vamos a hacer es almacenarlos en la base de datos. Para ello, vamos a usar el siguiente script:

```bash
python 3.store_embeddings.py
```

Este script se encargar치 de almacenar los embeddings en la base de datos. Si todo ha ido bien, deber칤as ver algo como esto en la interfaz de Qdrant:


### 2.1 Configuraci칩n de las colecciones en Qdrant

Quiz치s esta es la parte que m치s me cost칩 entender. En Qdrant, las colecciones son como tablas en una base de datos relacional. Cada colecci칩n tiene un nombre y contiene un conjunto de puntos (o embeddings) que est치n relacionados entre s칤. En este caso, hemos creado una colecci칩n llamada `youtube_guides` que contendr치 todos los embeddings que hemos generado a partir de los documentos de la documentaci칩n de YouTube. Las colecciones son la forma en la que Qdrant organiza los datos. Esta tiene una configuraci칩n asociada que tiene dos valores importantes:

- **Size**: Se 
- **Distance**: Este es el tipo de distancia que se va a usar para calcular la similitud entre los puntos. En este caso, hemos usado `Cosine` que es el m치s com칰n para este tipo de tareas. 

Aqu칤 tienes algunos ejemplos sencillos para entender cu치ndo usar cada una de las m칠tricas de distancia en Qdrant:

Producto escalar (Dot):

Ejemplo: Tienes vectores de caracter칤sticas de productos en una tienda online, y todos los vectores est치n normalizados.
Uso: Utiliza el producto escalar para encontrar productos similares bas치ndote en caracter칤sticas normalizadas como color, tama침o, y categor칤a.
Similitud del coseno (Cosine):

Ejemplo: Est치s comparando documentos de texto, como art칤culos de blog o descripciones de videos de YouTube.
Uso: Utiliza la similitud del coseno para encontrar documentos que tienen contenido similar, independientemente de la longitud del texto.
Distancia euclidiana (Euclid):

Ejemplo: Tienes datos de ubicaci칩n geogr치fica de usuarios en una aplicaci칩n de mapas.
Uso: Utiliza la distancia euclidiana para calcular la distancia directa entre dos puntos geogr치ficos y encontrar usuarios cercanos.
Distancia Manhattan (Manhattan):

Ejemplo: Est치s analizando datos de ventas donde cada vector representa las ventas de diferentes productos en diferentes regiones.
Uso: Utiliza la distancia Manhattan para medir la diferencia absoluta en ventas entre regiones, lo cual puede ser 칰til para identificar patrones de ventas.


Cada registro se llama punto y tiene un ID 칰nico. Este ID es el que vamos a usar para recuperar la informaci칩n m치s adelante. Por


## 3. Realizar consulta del usuario


#  Cu치l es el proceso completo?

```mermaid
graph TD
    A[Crear datos externos] --> B[Convertir datos a formato compatible]
    B --> C[Generar embeddings]
    C --> D[Almacenar embeddings en una base de datos]
    D --> E[Realizar consulta del usuario]
    E --> F[Recuperar informaci칩n relevante]
    F --> G[Generar respuesta con modelo LLM]
```





